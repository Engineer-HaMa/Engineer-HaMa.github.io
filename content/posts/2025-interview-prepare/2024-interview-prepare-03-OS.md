+++
title = "3. OS"
date = 2025-08-08

weight = 3
+++

# TL;DR
이 글은 2025년도 봄학기 KAIST 전산학부 대학원 면접을 준비하며, 면접 참고자료(OS)에 대한 대답을 정리한 글입니다.

문제에 대한 정답이 아니며, 제가 공부하며 생각한 바들을 정리한 것입니다.

후에 같은 목표로 면접을 준비하는 학우분들께 도움이 되기를 바랍니다.

이 풀이노트는 질문만 본 상태에서 답변한 내용에 대한 채점, 그리고 이 면접을 준비하며 이전에 한번 LLM과 함께 작성해본 답안이 이어져 있습니다.

# 문제

## Kernel

### Kernel을 필요에 의해 어느정도 수정했다고 하자. 이 kernel이 제대로 작동하는지를 알기 위해서 어떤 test를 해야 하나?

>  먼저 정적 분석을 가장 먼저 이용합니다. 타입 체커 등 다양한 정적분석기가 이용됩니다.
>  그 뒤 단위 테스트, 통합 테스트, 회귀 테스트 등 수정 부분으로부터 점차 범위를 늘려가며 테스트가 필요합니다.

정확히 질문의 의도를 모르겠어서 일단 gemini 답변을 메모해둡니다
수정된 커널이 제대로 작동하는지 확인하려면 여러 단계에 걸친 체계적인 테스트가 필요합니다. 테스트는 크게 **기본 기능 검증**, **안정성 및 부하 테스트**, 그리고 **성능 평가**로 나눌 수 있습니다.

---

### Interrupt란 무엇인가? interrupt를 두 종류로 나눈다면 어떻게 되는가? (software interrupt/hardware interrupt) 두 interrupt의 차이는 무엇인가? 두 interrupt의 handler 를 서로 구분해서 구현해야 하는 것이 좋은가, 아니어도 상관 없는가?

> 인터럽트란 특정 신호에 의해 프로그램의 흐름에서 벗어나 추가적인 코드를 실행하는 것입니다.
>
> 인터럽트는 크게 소프트웨어 인터럽트와 하드웨어 인터럽트로 나눌 수 있습니다.
> 소프트웨어 인터럽트와 하드웨어 인터럽트의 가장 큰 차이는 호출의 주체와 동기성입니다.
> 소프트웨어 인터럽트는 프로그램의 실행에 의해 호출되며 동기적입니다.
> 하드웨어 인터럽트는 외부 디바이스에 의해 발생하며 비동기적입니다.
>
> 두 인터럽트는 상황에 따라 우선순위에 차이가 있기 때문에 구현에 차이가 있습니다.
> 보통 하드웨어 인터럽트는 디바이스 전체에 영향을 미치기 때문에 우선적으로 해결되야 합니다.
> 소프트웨어 인터럽트는 단일 프로세스로 발생 범위가 제한되어 우선순위가 밀립니다.

인터럽트란 제어 흐름에서 일시적으로 벗어난 이벤트와 이를 처리하는 메커니즘을 의미합니다.
인터럽트는 크게 하드웨어 인터럽트와 소프트웨어 인터럽트로 나눌 수 있습니다.
하드웨어 인터럽트는 프로세서 외부 장치에서 비동기적으로 발생하는 이벤트입니다. 예를 들어, 키보드 입력, 마우스 클릭, 네트워크 패킷 수신 등이 있습니다.
소프트웨어 인터럽트는 프로그램 내부에서 발생하는 이벤트입니다. 예를 들어, 시스템 콜, 예외 처리 등이 있습니다.
https://www.geeksforgeeks.org/operating-systems/difference-between-hardware-interrupt-and-software-interrupt/
두 인터럽트의 핸들러를 구분해서 구현하는 것이 좋습니다.
먼저 둘은 발생 맥락이 다릅니다. 하드웨어 인터럽트는 외부 장치에서 발생하는 이벤트이고, 소프트웨어 인터럽트는 프로그램 내부에서 발생하는 이벤트입니다.
하드웨어 인터럽트는 코드와 상관없이 외부 장치에서 발생하는 이벤트이므로, 프로그램의 흐름과 무관하게 발생할 수 있고, 최대한 빠르게 처리해야 합니다.
소프트웨어 인터럽트는 프로그램 내부에서 발생하는 이벤트이므로, 프로그램의 흐름에 따라 발생할 수 있고, 상대적으로 느리게 처리해도 됩니다.
이러한 우선순위의 차이로 구분하여 구현하는 것이 좋습니다.

---

### 시스템 콜과 인터럽트의 차이는? 인터럽트가 걸리면 어떤 일이 일어나고 처리 후에 어떻게 이전 상태로 돌아가는가

> 인터럽트는 시스템 콜을 포함하는 개념입니다.
> 사용자가 의도적으로 약속한 인수를 채우고 특정 인터럽트를 발생시켜(트랩) 시스템 콜을 실행할 수 있습니다.
>
> 인터럽트가 걸리면 프로세서는 인터럽트 서비스 루틴으로 진입합니다.
> ISR에서 기본적으로 현재 프로그램의 상태를 저장하고, 나머지 루틴을 실행한 뒤, 프로그램의 상태를 복구합니다.
> 이를 통해 인터럽트 처리 후 이전 상태로 돌아갈 수 있습니다.

시스템 콜은 사용자 프로그램이 운영체제의 서비스를 요청하는 메커니즘으로, 소프트웨어 인터럽트의 일종입니다.
인터럽트는 프로그램 흐름에서 동기, 비동기적으로 발생하는 이벤트로, 하드웨어 인터럽트와 소프트웨어 인터럽트로 나눌 수 있습니다.
인터럽트가 발생하면 프로세서는 운영체제가 등록한 핸들러를 호출하고, 해당 이벤트를 처리합니다.
처리 후에 프로세서는 이전 상태로 돌아가기 위해, 인터럽트 발생 전의 레지스터 상태를 저장하고, 해당 상태로 복원합니다. (운영체제 + 프로세서의 역할)

---

### Thread와 process의 차이는 무엇인가?

> 둘의 차이는 주소 공간의 공유 여부입니다.
> 스레드간에는 주소 공간을 공유할 수 있지만,
> 프로세스간에는 shared memory 같은 특정 IPC 매커니즘을 이용하지 않는다면 주소공간을 공유할 수 없습니다.
>
> 외에도 TCB, PCB의 구성 요소에 차이가 있고, 일반적으로 프로세스 간에 고립된 자원은 스레드간에 공유됩니다.

프로세스와 스레드의 가장 큰 차이는 주소 공간의 공유 여부입니다.
프로세스는 독립적인 주소 공간을 가지며, 서로 다른 프로세스 간에 메모리를 공유하지 않습니다.
스레드는 같은 프로세스 내에서 실행되는 실행의 단위로, 같은 주소 공간을 공유합니다.
때문에 IPC에 의한 비용이 발생하지 않습니다.

---

### IPC가 무엇인가?

> Inter Process Communication의 약자로, 프로세스간에 데이터를 주고받는 방식입니다.
> 대표적으로 메세지 큐, shared memory 등이 있습니다.

Inter Process Communication의 약자로, 프로세스 간 통신을 의미합니다.
프로세스 간의 데이터를 주고받기 위한 메커니즘으로, 파이프(파일 시스템), 소켓, 메시지 큐, 공유 메모리 등이 있습니다.

---

### Thread끼리 context switching 하는 과정에 대해 설명하시오. 같은 프로세스 내부의 thread들끼리 전환되는 것과 다른 프로세스간의 thread 까리 전환되는 것이 어떻게 다른가?

> 같은 프로세스 내에서의 컨텍스트 스위치일 경우, TCB만 교체하면 되고,
> 다른 프로세스 간의 스레드 컨텍스트 스위치일 경우 PCB도 교체해야 합니다.
> 다른 프로세스간의 컨텍스트 스위치에서 PCB가 교체될 땐 페이지 테이블, 파일 테이블 등이 바뀌어 시간이 더 걸립니다.

스레드 간의 컨텍스트 스위치는 레지스터 상태를 저장하고 복원하는 과정으로 이루어집니다. 이는 스택 포인터의 전환을 포함합니다.
같은 프로세스 간의 스레드 간 전환은 주소 공간을 공유하므로, 메모리 맵을 변경할 필요가 없습니다. 따라서 빠르게 전환할 수 있습니다.
다른 프로세스 간의 스레드 간 전환은 주소 공간이 다르므로, 메모리 맵을 변경해야 합니다. 따라서 더 많은 오버헤드가 발생합니다.
이 오버헤드에는 페이지 폴트, 캐시 미스 등이 포함됩니다. 또한, 프로세스 간의 스레드 전환은 더 많은 레지스터 상태를 저장하고 복원해야 하므로, 더 많은 시간이 소요됩니다.
TLB flush가 가장 큰 시간 차이를 만듭니다.

---

### Non-preemptive scheduling이란?

> 비선점형 스케줄링은 프로세스가 코어를 점유중일때 다른 프로세스가 이를 사용하지 못하는 형식의 스케줄링입니다.
> 즉, 실행중인 프로세스가 이를 양보하기 전까지 다른 프로세스는 이를 사용하지 못합니다.

비선점 스케줄링은 현재 실행 중인 프로세스가 자발적으로 CPU를 양보할 때까지 기다리는 방식입니다.
즉, 프로세스가 CPU를 점유하고 있는 동안에는 다른 프로세스이 CPU를 사용할 수 없습니다.
이 방식은 프로세스가 CPU를 양보하지 않는 한, 다른 프로세스가 CPU를 사용할 수 없으므로, CPU 사용률이 낮아질 수 있습니다.
비선점 스케줄링은 주로 Real time os로 불리는 실시간 시스템에서 사용됩니다.

---

### 요즘 많은 사람들이 각각 자신만의 스마트폰을 사용하고 있다. 이처럼 각 개인 스마트폰을 위하여 process system을 design하려고 한다. 스마트폰에서 각 application이 하나의 process로 독립해서 실행하는 것이 나을까? 아니면, 하나의 thread로 만들어져서 실행하는 것이 나을까? 어느 쪽이 나을지 결정하고, 그 이유 를 설명하라

> 각 애플리케이션을 프로세스로 실행하는 것이 낫습니다.
> 프로세스와 스레드간의 트레이드오프는 성능과 고립인데,
> 현대 디바이스가 충분히 빠르고 보안 문제가 더 위험하기 때문입니다.

스마트폰에서 각 애플리케이션이 하나의 프로세스로 독립적으로 실행하는 것이 좋습니다.
각 애플리케이션이 독립적인 프로세스로 실행되면, 애플리케이션 간의 메모리 충돌을 방지할 수 있습니다.
또한, 애플리케이션이 비정상적으로 종료되더라도 다른 애플리케이션에 영향을 주지 않습니다.
또한 보안적인 측면에서도 프로세스 간의 메모리 공간이 분리되어 있어, 악성 애플리케이션이 다른 애플리케이션의 데이터를 읽거나 수정하는 것을 방지할 수 있습니다.
다량의 프로세스가 동시에 실행되면 성능 저하가 발생할 수 있지만, 현대의 스마트폰은 멀티코어 CPU를 사용하고 있어, 여러 프로세스를 동시에 실행하는 데 충분한 성능을 제공합니다.

---

## Concurrency

### Sequential program과 multithread program에서 error detection에 대한 차이점에는 어떤 것이 있나?

> Sequential 프로그램에선 발생하지 않지만 multithread로 동작하면서 발생하는 에러가 많아집니다.
> 대표적인 예시로 데드락, 레이스 컨디션 등이 있습니다.
> 때문에 기존에 사용하던 정적 분석 도구, 테스트 도구들을 통해 검출되지 않는 에러들이 있고, 이를 추가로 검사해야 합니다.

멀티스레드 프로그램에서는 메모리의 공유로 인해 다양한 동기화 문제가 발생할 수 있습니다.
예를 들어, 레이스 컨디션 데드락 등이 있습니다.
이러한 문제는 동기화 메커니즘(뮤텍스, 세마포어 등)을 사용하여 해결할 수 있지만, 이로 인해 프로그램의 복잡성이 증가하고
디버깅이 어려워질 수 있습니다.

---

### Critical section이란?

> 크리티컬 섹션은 멀티스레드 프로그래밍에서 여러 스레드 중 하나만 동시에 실행해야 하는 코드를 의미합니다.
> 뮤텍스, 락, 세마포어 등을 이용하여 여러 스레드의 실행을 방지합니다.

크리티컬 섹션은 여러 스레드가 동시에 접근할 수 없는 공유 자원에 대한 코드 블록을 의미합니다.
크리티컬 섹션에 접근하는 스레드는 다른 스레드가 해당 섹션에 접근하지 못하도록 mutual exclusion을 보장해야 합니다.
이를 위해 뮤텍스, 세마포어 등의 동기화 메커니즘을 사용합니다.

---

### 세마포어의 개념은? 주요 연산 2가지는? 어떻게 구현해야 하는가?

> 세마포어는 시그널과 웨이트 두 연산과 정수 카운터로 이루어져 있습니다.
> 웨이트을 통해 정수 카운터를 낮추고, 만약 음수라면 슬립합니다.
> 시그널을 통해 정수 카운터를 높이고 만약 0 이상이라면 대기중인 스레드 중 하나를 깨웁니다.
> 아키텍처별로 제공하는 atomic 연산 cas를 통해 구현합니다.


세마포어는 공유 자원에 대한 접근을 제어하는 동기화 메커니즘입니다.
세마포어는 두 가지 주요 연산을 가지고 있습니다: wait(P)와 signal(V)입니다.
wait(P) 연산은 세마포어의 값을 읽고 감소시키려고 합니다. 만약 읽은 값이 0 이하였다면 대기 상태로 전환합니다.
signal(V) 연산은 세마포어의 값을 증가시키고, 대기 중인 프로세스가 있다면 그 프로세스를 깨웁니다.
가장 간단한 구현은 세마포어를 정수로 표현하고, wait와 signal 연산을 원자적으로 수행하는 것입니다. -> 따라서 하드웨어가 원자적 연산을 지원해야 합니다.
이를 위해 뮤텍스나 spinlock을 사용하여 세마포어의 값을 읽고 쓰는 작업을 보호할 수 있습니다.

---

## Virtual Memory

### Virtual Address와 Virtual memory에 대해 설명하시오

> 가상 주소는 프로세스가 메모리에 접근할 때 이용하는 주소입니다.
> 가상 메모리 시스템은 이를 바탕으로 물리 메모리를 매핑하고 접근하는 기술힙니다.

가상 주소는 프로세스가 사용하는 주소 공간을 의미합니다. 프로세스는 가상 주소를 사용하여 메모리에 접근합니다.
가상 메모리는 프로세스가 사용하는 가상 주소 공간을 실제 물리 메모리에 매핑하는 기술입니다.
가상 메모리를 사용하면 프로세스는 실제 물리 메모리보다 더 큰 주소공간을 독립적으로 사용할 수 있습니다.

---

### 어떤 C program으로 작성되어 수행중인 process가 있다고 가정하자. C언어에서는 직접적으로 주소를 변수에게 지정해 줄 수 있다. 만약 주소 1, 2, 3, 4에 변수를 잡아서 어떤 일을 수행하는 process라고 하자. 이 process를 한 시스템에 동시에 두번 수행 시켰다. 그랬을 때 한 프로세스가 1, 2, 3, 4 주소에 있는 변수를 바꿨을 때 다른 프로세스의 변수들에도 영향을 끼치는가?

> 영향을 미치지 않습니다. 주소공간이 분리되어 있기 때문입니다.

아니요, 가상 메모리를 사용하기 때문에 각 프로세스는 독립적인 가상 주소 공간을 가지므로,
두 프로세스의 같은 가상 주소는 서로 다른 물리 주소에 매핑됩니다.
만약 이 변수들이 커널 상태와 연관된 변수라면, 영향을 미칠 수 있습니다.
예를 들어 파일 디스크럽터를 생성하고 포크하는 경우 두 프로세스가 같은 파일 디스크럽터를 공유할 수 있습니다. (v-node의 공유) -> 정확하지 않음

---

### C로 숫자로 직접 입력된 주소를 참조하는 프로그램을 짜서 컴파일한 후, 두 개를 실행시켰다고 하자. 그러면 이 두 프로세스는 물리적으로 같은 곳을 참조하나? 만약 아니라면, 어떻게 서로 다른 물리적 공간을 참조할 수 있나?

> 유저 공간 주소를 참조할 경우 가상 메모리에 의해 서로 다른 공간을 참조합니다.
> 만약 커널 공간을 참조하거나 포크 이후 같은 주소를 참조했다면 같은 공간일 수 있습니다.

아니요, 두 프로세스는 서로 다른 가상 주소 공간을 가지므로, 같은 가상 주소를 참조하더라도 서로 다른 물리 주소를 참조합니다.
가상 메모리 시스템은 각 프로세스에 대해 독립적인 가상 주소 공간을 제공합니다. 따라서 두 프로세스가 같은 가상 주소를 참조하더라도, 운영체제는 이를 서로 다른 물리 주소로 매핑합니다.
다이내믹 링킹이 반례가 될 수 있음

---

### Logical address와 physical address의 차이는 무엇인가?

> 논리 주소는 가상 주소로, 프로세서가 사용하는 주소입니다.
> 이를 물리 주소로 변환하기 위해 페이지 테이블과 mmu가 필요합니다.

논리 주소는 프로세스가 사용하는 가상 주소 공간의 주소입니다. 프로세스는 논리 주소를 사용하여 메모리에 접근합니다.
물리 주소는 실제 물리 메모리의 주소입니다. 운영체제는 논리 주소를 물리 주소로 매핑하여 프로세스가 메모리에 접근할 수 있도록 합니다.
일반적으로 페이징 기법을 사용하여 논리 주소를 물리 주소로 변환합니다.
페이징 기법은 논리 주소 공간을 페이지 단위로 나누고, 물리 주소 공간을 프레임 단위로 나누어, 페이지와 프레임을 매핑하는 방식입니다.

---

### Logical address를 physical address로 바꾸어주는 hw가 무엇인가?

> mmu로, 현대 마이프로프로세서에 보통 같이 들어 있습니다.

MMU(Memory Management Unit)입니다. MMU는 논리 주소를 물리 주소로 변환하는 하드웨어입니다.
일반적으로 현대 프로세서에는 MMU가 내장되어 있습니다.
MMU는 페이지 테이블을 사용하여 논리 주소를 물리 주소로 변환합니다.
페이지 테이블은 논리 주소와 물리 주소의 매핑 정보를 저장하는 데이터구조입니다.

---

### 프로세스는 가상 메모리 주소로 어떻게 실제 메모리 주소를 찾아가는가?

> 프로세스는 페이지 테이블을 통해 물리 메모리 주소를 찾아갑니다.
> 이를 수정하여 페이지 할당을 변환합니다.

프로세스는 페이지 테이블을 사용하여 가상 메모리 주소를 물리 메모리 주소로 변환합니다.
페이지 테이블은 가상 주소 공간의 각 페이지가 물리 주소 공간의 어떤 프레임에 매핑되는지를 저장합니다.

---

### OS의 캐시 메모리의 사이즈를 구하기 위한 프로그램을 어떻게 구현하면 되는가?

> LRU 캐시를 가정하고 설명드리겠습니다.
> 하나의 배열을 두번 순회하는 코드를 짜고,
> 배열크기를 조금씩 늘리다보면 실행시간이 급격히 늘어나는 지점을 찾을 수 있습니다.
> 이때 배열의 크기가 캐시 크기와 비슷합니다.

배열의 크기를 늘려가면서, 배열에 값을 넣고, 해당 배열의 주소를 출력하는 프로그램을 작성할 수 있습니다.
이때, 배열의 크기가 커질수록 선형적으로 실행 시간이 증가하다가 어느 순간 급격히 느려지는 크기를 찾을 수 있고, 캐시 미스가 발생하는 지점을 확인할 수 있습니다.

---

## Paging

### Paging이 무엇인가? paging을 할 때 어떻게 실제 메모리 주소에 데이터를 전송하는가? page table에는 어떤 항목이 저장되는가? page table은 어디에 저장되는가? page table이 메모리에 저장되면, paging을 할 때 메모리를 두 번 참조해야 되는데, 좀 더 빠르게 하는 방법은 없는가? TLB에는 어떤 항목이 저장되는가?

> 페이징을 가상 메모리를 페이지 단위로 물리 메모리 프레임에 매핑하는 기술입니다.
> 페이징을 하면 mmu가 가상 메모리를 물리 메모리로 번역하여 실제 메모리 주소에 데이터를 전송합니다.
> 페이지 테이블에는 가상 페이지 넘버, 물리 프레임 넘버, valid 비트, rw 관련 비트 등이 저장됩니다.
> 페이지 테이블은 커널 공간에 저장되어, 페이지 포인터 레지스터가 가리키고 있습니다.
> TLB를 이용하는 것이 보통이고, 페이징 구현을 바꾸는 케이스도 있습니다.
> TLB에는 가상 메모리 주소, 물리 메모리 주소 쌍이 저장되고, valid bit가 있습니다.

페이징은 가상 메모리 주소 공간을 고정 크기의 페이지로 나누고, 물리 메모리 주소 공간을 프레임으로 나누어, 페이지와 프레임을 매핑하는 기법입니다.
페이지 테이블은 가상 주소 공간의 각 페이지가 물리 주소 공간의 어떤 프레임에 매핑되는지를 저장합니다.
페이지 테이블은 커널 주소 공간에 저장됩니다.
페이지 테이블이 메모리에 저장되면, 페이지를 참조할 때마다 페이지 테이블을 참조해야 하므로, 메모리를 두 번 참조하게 됩니다.
이를 해결하기 위해 TLB(Translation Lookaside Buffer)를 사용합니다. TLB는 페이지 테이블의 일부를 캐시하여, 페이지 테이블을 참조하는 횟수를 줄입니다.
TLB에는 페이지 번호와 해당 페이지가 매핑된 프레임 번호가 저장됩니다. 즉 가상 주소에서 페이지 번호를 추출하면 바로 TLB에서 프레임 번호를 찾을 수 있습니다.

### Virtual memory에서 page replacement policy에는 어떤 것이 있는가? LRU의 단점은?

> LIFO, LRU, LFU 등이 있습니다.
> LRU는 구현이 어렵고, 탐색에 시간이 걸리고, 타임스탬프를 저장해야 합니다.
> 이를 개선하기 위해 two-chance clock 등으로 근사하여 구현합니다.

가상 메모리에서 페이지 교체 정책에는 LRU(Least Recently Used), FIFO(First In First Out), LFU(Least Frequently Used), Random 등이 있습니다.
LRU는 가장 오랫동안 사용되지 않은 페이지를 교체하는 정책입니다.
LRU의 단점은 구현이 복잡하고, 페이지 교체를 위한 추가적인 메모리 오버헤드가 발생한다는 것입니다.
LRU를 구현하기 위해서는 페이지의 사용 시간을 추적해야 하므로, 추가적인 데이터 구조가 필요합니다.
또한, LRU는 페이지 교체가 발생할 때마다 페이지의 사용 시간을 업데이트해야 하므로, 성능 저하가 발생할 수 있습니다.
linux는 clock-based second chance algorithm을 통해 LRU를 근사적으로 구현합니다.

---

### 운영 체제에서 memory management 기법중 하나로 paging이 많이 사용되고 있다. Paging 기법의 장⋅단점으로는 무엇이 있으며, hierarchical paging 혹은 inverted page table은 어떤 환경에서 유리한가?

> 페이징 기법은 각 프로세스가 독립된 주소공간을 가질수있고, 물리 메모리보다 큰 주소공간을 사용할 수 있다는 장점이 있습니다.
> 하지만 프로세스가 늘어날수록 페이지 테이블의 차지하는 메모리가 증가하고 fault penalty가 크다는 단점이 있습니다.
> 게층 페이지는 페이지 테이블 용량을 줄이기 위해 페이지 단위로 페이지 테이블 크기를 줄이는 것입니다.
> 32비트에서 2계층, 64비트에서 4계층을 주로 이용합니다.
> inverted page table은 물리 주소 하나에 하나의 가상 페이지 넘버만 매핑시키는 페이지 테이블입니다.
> 이를 위해 pid와 같은 추가적인 키가 필욯바니다.

페이징 기법의 장점은 다음과 같습니다:
* **메모리 보호:** 각 프로세스는 독립적인 가상 주소 공간을 가지므로, 프로세스 간의 메모리 충돌을 방지할 수 있습니다
* **효율적인 메모리 사용:** 가상 메모리를 사용하여 실제 물리 메모리보다 더 큰 주소 공간을 사용할 수 있습니다. 이를 통해 프로세스는 필요한 만큼의 메모리를 동적으로 할당받을 수 있습니다.
* **단편화 문제 해결:** 가상 메모리를 사용하여 물리 메모리의 단편화 문제를 해결할 수 있습니다. 페이지 단위로 메모리를 할당하므로, 물리 메모리의 단편화 문제를 최소화할 수 있습니다

페이징 기법의 단점은 다음과 같습니다:
* **오버헤드:** 페이지 테이블을 유지해야 하므로, 추가적인 메모리 오버헤드가 발생합니다. 페이지 테이블이 커질수록 오버헤드가 증가합니다.
* **TLB 미스:** 페이지 테이블을 참조할 때마다 TLB를 참조해야 하므로, TLB 미스가 발생할 수 있습니다
* **페이지 교체:** 페이지가 메모리에 없을 때 페이지 교체가 발생하므로, 페이지 폴트가 발생할 수 있습니다. 페이지 폴트가 발생하면 디스크 I/O가 발생하므로, 성능 저하가 발생할 수 있습니다

계층적 페이징(Hierarchical Paging)은 페이지 테이블이 너무 커지는 문제를 해결하기 위해 사용됩니다.
페이지 테이블을 여러 레벨로 나누어, 각 레벨에서 필요한 페이지만을 메모리에 유지합니다.
inverted page table은 페이지 테이블의 크기를 줄이기 위해 사용됩니다.
프레임 번호와 가상 페이지 번호의 매핑을 유지하는 대신, 물리 메모리의 프레임에 대한 단일 테이블을 유지합니다.
두 기법 모두 페이지 테이블의 크기가 커지는 문제를 해결하기 위해 사용됩니다.

---
